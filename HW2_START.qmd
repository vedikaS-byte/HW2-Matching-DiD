---
title: "ðŸŒ¬ï¸ðŸ—³ Assignment 2: Wind Turbines, Matching, and Difference-in-Differences"
subtitle: "Replicate causal inference identification strategies in Stokes (2015) "
author: "EDS 241 / ESM 244 (DUE: 2/4/26)"
format:
  html:
    theme: sketchy
    css: styles.css
date: "January 26, 2026"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

### Assignment instructions

Working with classmates to troubleshoot code and concepts is encouraged. If you collaborate, list collaborators at the top of your submission.

All written responses must be written independently (in your own words).

Keep your work readable: Use clear headings and label plot elements thoughtfully.

Assignment submission (YOUR NAME): Vedika Shirtekar

------------------------------------------------------------------------

### Introduction

In this assignment you will be doing political weather forecasting except the â€œstormsâ€ we care about are electoral swings that might follow local wind turbine development.

In Stokes (2015), the idea is that a policy with diffuse benefits (cleaner electricity) can create concentrated local costs (turbines nearby), and those local opponents may â€œsend a signalâ€ at the ballot box (i.e., NIMBYISM). Your job is to use two statistical tools:

-   Matching: Can we create a more apples-to-apples comparison between precincts that did vs. did not end up near turbine proposals?
-   Fixed effects + Difference-in-Differences: Can we use repeated elections to estimate how within-precinct changes in turbine exposure relate to changes in incumbent vote share?

------------------------------------------------------------------------

### Learning goal: Replicate the matching and fixed effects analyses from study:

> Stokes (2015): *"Electoral Backlash against Climate Policy: A Natural Experiment on Retrospective Voting and Local Resistance to Public Policy*.

-   **Study:** [Stokes (2015) - Article](https://drive.google.com/file/d/1y2Okzjq2EA43AW5JzCvFS8ecLpeP6NKh/view?usp=sharing)
-   **Data source:** [Dataverse-Stokes2015](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDUGCC)

::: callout
`NOTE:` Replication of study estimates will be approximate. An alternative matching procedure and fixed effects estimation package are utilized in this assignment for illustration purposes.
:::

------------------------------------------------------------------------

### Setup: Load libraries

0.  Load libraries (+ install if needed)

```{r}

library(tidyverse)
library(here)
library(janitor)
library(jtools)

library(gtsummary)
library(gt)

library(MatchIt) # matching
library(cobalt)  # balance + love plots

library(fixest) # fast fixed effects
library(scales) # plotting

```

------------------------------------------------------------------------

### Part 1: Study Background

#### **1A.** Dive into the details of the study design and evaluation plan

> Goal: Get familiar with the study setting, environmental issue, and policy under evaluation.

::: callout
`NOTE:` Read over study to inform your response to the assignment questions. For this assignment we will skip-over sections that describe the *Instrumental Variables* identification strategy. We will cover instrumental variable designs weeks 6-7.
:::

**1A.Q1** Summarize the environmental policy issue, the outcome of interest, and the intervention being evaluated. Be sure to include a brief description of each of the following key elements of the study: unit of analysis, outcome, treatment, comparison group):

*Response:* In her 2015 analysis of Ontarioâ€™s Green Energy Act passed in 2009, Leah Stokes examines how local resistance to renewable energy infrastructure creates an environmental policy issue where concentrated local costs lead to "spatially distorted signaling" (Stokes, 2015, pg. 1). The study's intervention was the removal of local planning authority to fast track wind energy projects, creating a natural experiment where communities could not select out of receiving turbines (Stokes, pg. 2). The precinct was utilized as the primary unit of analysis, where Stokes evaluated the outcome of electoral/political punishment, which was measured by changes in the incumbent Liberal Party's voter share and voter turnout (Stokes, pg. 6). The treatment was defined as having an industrial-scale wind project (\> 10 megawatts) proposed or operational within a precinct (Stokes, pg. 7). The comparison group consisted of similar precincts without turbines within the same wind-resource heavy districts, analyzed using fixed effects and variable estimators to ensure that the results were not biased by the project siting (Stokes, pg. 1 and 3).

**1A.Q2** Why might turbine proposals be correlated with baseline political preferences or rural areas? Provide 2 plausible mechanisms, and explain why that creates confounding.

*Response:* Turbine proposal can be correlated with baseline political preferences and rural areas through two primary mechanisms: resource availability and strategic siting. First, developers may prioritize regions with the highest/fastest wind speeds which are naturally found in open rural landscapes more often than in urban areas. Second, rural areas can have lower property values and less political influence, so companies may target these areas to minimize legal and/or socioeconomic opposition. This creates confounding influence because these rural communities may already have been trending towards opposition parties due to economic and/or cultural factors. As a result, it is not entirely possible to know if a drop in the incumbents votes was actually caused by the wind turbines or if the turbines were placed in areas that were already planning to vote against the government; careful analysis is required to control for confounding influence on changes in the incumbent voter share.

------------------------------------------------------------------------

#### **1B.** Break down the causal inference strategy and identify threats to identification:

**1B.Q1** What is the key identifying assumption for a fixed effects / Difference-in-Difference design? Explain how this assumption when satisfied provides evidence of causal effect:

*Response:* The key identifying assumption for a fixed effects/Diff-in-Diff design is the parallel trends assumption which assumes that if the treatment (the wind turbines) had never occurred, then the treatment and control groups would have observed the same average change in their voting patterns over time. This assumption provides evidence for a causal effect by allowing the control group to serve as a "counterfactual" or what would have occurred to the treated precincts without the policy. When trends are parallel, any new gap that appears between the two groups after the turbines are introduced may be attributed specifically to the policy rather than on pre-existing differences or general political shifts within precincts.

**1B.Q2** What is the reason for using a fixed effects approach from a causal inference perspective? Summarize within the context of study (in your own words).

*Response:* A fixed effects approach is utilized to ensure a fair or apples-to-apples comparison by removing all permanent differences between locations (precincts) that could potentially bias the outcome (changes in incumbent voter shares). In this study, every precinct is unique; some precincts are naturally more conservative, more rural, or have differing local economies. If Stokes simply compared a wind turbine precinct to a non-wind turbine precinct, then it would not be clear if the difference in voting was caused by the turbine or by pre-existing characteristics such as baseline voting preferences or resource availability (ex. more access to higher wind speed). By using fixed effects, the study observes each precinct compared only to its own past effectively "cancelling out" everything that stays the same over time. This allows one to isolate the wind turbine as the specific cause of the electoral reaction rather than being misled by baseline local characteristics in each precinct.

**1B.Q3** What part of the SUTVA assumption is most likely violated in the context of this study design (and why)?

*Response:* In the context of this study, the part of the SUTVA assumption that is most likely violated is the "no interference" or "no spillover(s)" condition. This assumption requires that the treatment status of one unit (precinct) does not affect the outcome of another unit. However, wind turbines are large scale projects that can span or are visible across precinct boundaries. A voter living in a control precinct (without a turbine) could still live very close to a turbine located in an adjacent treated precinct. As a result, a voter in a control precinct could experience the same noise, visual impacts, or property value concerns in a neighboring precinct with a turbine. If people in the control precincts (without turbines) also vote against the government because they are impacted by turbines in a neighboring area, then the gap between the two groups shrinks. This makes the policy's impact look smaller than it actually is, causing the study to underestimate the true level of electoral backlash or punishment (the change in incumbent voter share is underestimated).

**1B.Q4** Why does spillover matter when estimating an unbiased treatment effect?

*Response:* Spillover matters because it contaminates the controlled or "clean" comparison between groups. In a perfect study, the control group should be completed unaffected by the policy implementation to show what would have happened naturally. If the effects spill over into the control group (ex. if neighbors without turbines also vote against the government), the control group is no longer an unbiased/neutral baseline. As a result, the two groups appear more alike than they actually are, shrinking the "gap" between them and leading the researcher(s) to underestimate the true impact of the policy.

**1B.Q5** How do the authors assess the risk of spillovers, and what analytic choice do they make to attempt to mitigate the risk that spillover biases the causal estimate?

*Response:* The author evaluates potential spillovers by examining how voting changes with distance from wind projects in 1 km increments and finds that negative effects on the governmentâ€™s vote share persist up to at least 3 km away. To avoid bias, Stokes removes all precincts within 3 km of a turbine from the control group. This ensures that treated precincts are compared only to areas unlikely to be affected by turbine projects, preventing spillovers from making the policy appear weaker than it actually is.

------------------------------------------------------------------------

### Part 2: Matching

------------------------------------------------------------------------

We will start by evaluating the 2007 survey (cross-sectional) data. Treatment is defined by whether a precinct is near a turbine proposal (within 3 km).

> Goal: Match precincts using pre-treatment covariates and then estimate the effect of proposed wind turbines on incumbent vote share.

#### **2A.** Load data for matching

1.  Read in data file `stokes15_survey2007.csv`
2.  Code `precinct_id` and `district_id` as factors
3.  Take a look at the data

```{r}
match_data <- read.csv("data/stokes15_survey2007.csv")

match_data <- match_data %>% mutate(precinct_id = as.factor(precinct_id), district_id = as.factor(district_id))
```

**2A.Q1** Intuition check: **Why match?** Explain rationale for using this method.

*Response:* The rationale for using matching is to address selection bias and ensure that the treated precincts (near wind turbine proposals) are directly comparable to control precincts. Turbine locations are not randomly assigned and are instead often placed in rural areas with specific geographic and political characteristics. Matching allows a researcher to pair each treated precinct with a control precinct that has nearly identical pre-treatment features (ex. past voting history or demographics). This enables a "balanced" dataset where the only significant difference between the two groups is the presence of a turbine proposal, allowing for a more accurate estimate of the policy's causal effect on the incumbent's vote share. From a logistical perspective, matching can also be used to adjust for differences in the number and size of precincts between survey years, helping account for these discrepancies over time.

------------------------------------------------------------------------

#### **2B.** Check imbalance (before matching)

-   Create a covariate *balance table* comparing treated and control precincts
-   Treatment indicator: `proposed_turbine_3km`
-   Include pre-treatment covariates: `log_home_val_07`, `p_uni_degree`, `log_median_inc`, `log_pop_denc`
-   Use the `tbl_summary()` function from the `{gtsummary}` package.

```{r}

match_data %>% select(proposed_turbine_3km, log_home_val_07, p_uni_degree, log_median_inc, log_pop_denc) %>% 
    tbl_summary(
        by = proposed_turbine_3km, 
        statistic = list(
            all_continuous() ~ "{mean} ({sd})"
           # all_categorical() ~ "{n} ({p}%)"
        )
    ) %>% 
  modify_header(label ~ "**Covariate**") %>%
  modify_spanning_header(c("stat_1", "stat_2") ~ "**Group**")


```

**2B.Q1** Summarize the table output: Which covariates look balanced/imbalanced?

*Response:* The `log_pop_denc` appears to be the most imbalanced covariate. The `log_median_inc` seems to be the most balanced covariate between years, as well as `log_home_val_07` and `p_uni_degree` .

**2B.Q2** Describe in your own words why these covariates might be expected to confound the treatment estimate:

*Response (2-4 sentences):* Population density, education, income, and home value are all likely related to where wind turbine proposals occur and to political preferences. For example, less densely populated and lower income precincts may be more likely to host turbine proposals because land is cheaper. Additionally, these areas may differ in incumbent support compared to urban and/or wealthier precincts. Thus, it is important to control for these socioeconomic factors since differences in voter share could be incorrectly attributed to turbine proximity rather than underlying socioeconomic and demographic differences.

------------------------------------------------------------------------

**2B.Q3** Intuition check: What type of data do you need to conduct a matching analysis?

*Response:* A matching analysis requires observational data that include a treatment indicator, an outcome variable, and a set of pre-treatment covariates that influence both treatment assignment and the outcome. A sufficient and large pool of untreated observations is helpful such that treated units (precincts) can be matched to similar control units with comparable characteristics.

------------------------------------------------------------------------

### Conduct matching estimation using the {`MatchIt`} package:

ðŸ“œ [Documentation - MatchIt](https://kosukeimai.github.io/MatchIt/)

Learning goals:

-   Approximate the Mahalanobis matching method used in Stokes (2015)
-   Implement another common matching approach called `propensity score matching`

::: callout
`NOTE`: In the replication code associated with Stokes (2015) the {`AER`} package is used for Mahalanobis matching. In this assignment we use the {`MatchIt`} package. The results are comparable but will not be exactly the same.
:::

------------------------------------------------------------------------

### 2C. Mahalanobis nearest-neighbor matching

-   Conduct Mahalanobis matching\
-   Use nearest-neighbor match without replacement using Mahalanobis distance
-   Use 1-to-1 matching (match one control unit to each treatment unit)
-   Extract the matched data using `match.data()`

```{r}
set.seed(2412026)

match_model <- matchit(
     # Treatment_indicator ~  Pre_treatment_covariates
  proposed_turbine_3km ~ log_home_val_07 + p_uni_degree + log_median_inc + log_pop_denc,
  data = match_data, 
  method = "nearest",       # Nearest neighbor matching
  distance = "mahalanobis", # Mahalanobis distance
  ratio = 1,                # Match one control unit to one treatment unit (1:1 matching)
  replace = FALSE           # Control observations are not replaced
)

# Extract matched data
matched_data <- match.data(match_model)

```

```{r}
summary(match_model)
```

**2C.Q1** Using the `summary()` output: Which covariate had the largest and smallest `Std. Mean Diff.` before matching. Next, compare largest/smallest `Std. Mean Diff.` after matching.

*Response:* Prior to matching, the covariate with the smallest and largest Std. Mean Diff is `log_median_inc` and `log_pop_denc`, respectively. Following the matching analysis, the smallest and largest Std. Mean Diff is `log_median_inc` and `log_pop_denc`, respectively. Both mean differences decreased following the matching analysis, reducing the effect of the covariate influence on the treatment outcome.

------------------------------------------------------------------------

#### 2D. Create a "love plot" using `love.plot()` â¤ï¸

ðŸ“œ [Documentation - cobalt](https://ngreifer.github.io/cobalt/)

-   Plot mean differences for data before & after matching across all pre-treatment covariates
-   This is an effective way to evaluate how effective matching was at achieving balance.

------------------------------------------------------------------------

-   Make a love plot of standardized mean differences (SMDs) before vs after matching.
-   Include a threshold line at 0.1.
-   In love plot display `mean.diffs`

```{r}

new_names <- data.frame(
    old = c("log_home_val_07", "p_uni_degree", "log_median_inc", "log_pop_denc"),
    new = c("Home Value (log)", "Percent University Degree",
            "Median Income (log)", "Population Density (log)"))

# Love plot
love.plot(match_model, stats = "mean.diffs",
          thresholds = c(m = 0.1),
          var.names = new_names)

```

**2D.Q1** Interpret the love plot in your own words:

*Response:* The love plot shows that the matching process was very successful in achieving a covariate balance. Prior to matching (pink), there are large differences between the treatment and control groups, especially between population density and university degree percentages. After matching (blue), the Std. Mean Diffs for all covariate variables shifted significantly toward zero and now fall within the threshold established by the dashed lines. The love plot indicates that the matched turbine and non-turbine precincts are now statistically similar across all these variables, allowing for a fairer comparison of the turbine's effect on voting.

------------------------------------------------------------------------

### Propensity score matching

------------------------------------------------------------------------

#### 2E. Propensity Score Matching (PSM)

-   Estimate 1:1 nearest-neighbor Propensity Score Matching
-   Same code as above except change `distance = "logit"`

```{r}

set.seed(2412026)

propensity_scores <- matchit(
     # Treatment_indicator ~  Pre_treatment_covariates
  proposed_turbine_3km ~ log_home_val_07 + p_uni_degree + log_median_inc + log_pop_denc,
  data = match_data, 
  method = "nearest",       # Nearest neighbor matching
  distance = "logit", # Logit distance
  ratio = 1,                # Match one control unit to one treatment unit (1:1 matching)
  replace = FALSE           # Control observations are not replaced
)

# Extract matched data
propensity_matched_data <- match.data(propensity_scores)

summary(propensity_scores)
```

------------------------------------------------------------------------

#### Create table displaying covariate balance using `cobalt::bal.tab()`

ðŸ“œ [Documentation - cobalt](https://ngreifer.github.io/cobalt/)

Use `bal.tab()` to report balance before and after matching.

```{r}
new_names_propensity <- data.frame(
    old = c("log_home_val_07", "p_uni_degree", "log_median_inc", "log_pop_denc"),
    new = c("Home Value (log)", "Percent University Degree",
            "Median Income (log)", "Population Density (log)"))

print("Propensity Score Adjusted Differences:")
bal.tab(propensity_scores, 
        var.names = new_names_propensity) 

print("Mahalanobis Adjusted Differences:")
bal.tab(match_model, 
        var.names = new_names_propensity) 
```

**2E.Q1** Compare Mahalanobis vs propensity score matching. Which method did a better job at achieving balance?

*Response:* The Mahalanobis distance matching analysis is better at achieving a balance because the adjust differences are moved closer to zero for most of the covariates. For example, the difference for `p_uni_degree` is significantly smaller under the Mahalanobis matching approach (-.006) compared to the propensity score matching (0.0457). The Mahalanobis approach also achieved a nearly perfect balance for `log_median_inc` with a difference of .0002. Essentially, the standardized mean differences under the Mahalanobis approach are closer to 0 within the narrower defined interval; the Mahalanobis approach is more precise in minimizing the gaps between the treated and control groups that enable more identical comparisons for the causal analysis.

------------------------------------------------------------------------

#### 2F. Estimate an effect in the matched sample

Using the matched data (Mahalanobis method), estimate the effect of treatment on the change in incumbent vote share (`change_liberal`).

```{r}
reg_match <- lm(change_liberal ~ proposed_turbine_3km, data = matched_data)
summ(reg_match, model.fit = FALSE)
```

**2F.Q1** Have you identified a causal estimate using this approach: Why or why not?

*Response:* This approach identifies a causal estimate that is conditional on whether the matching method has properly balanced the covariates appropriately. The Mahalanobis matching method helps balance treated and control units on identified covariates, making the groups more comparable prior to estimating the effect of proposed turbine proximity on the change in incumbent vote share. Under the assumption that all relevant confounders (ie. `log_home_val_07, p_uni_degree, log_median_inc, log_pop_denc`) are observed and properly matched, the estimated statistically significant coefficient can be interpreted as a causal effect (p \< .05) .

**2F.Q2** When using a matching method, what is the main threat to causal identification?

*Response:* The main threat to causal identification when using matching is selection on unobserables. While matching ensures that the treated and control groups are balanced on the observed covariates (ex. demographics and income in existing data), it will not account for hidden factors that the researcher(s) did not measure. For example, if people in turbine precincts were already more concerned about government intervention for reasons not explained or captured by the data, then the unobserved concern rather than the turbines could drive the change in vote share. As a result, matching only balances what is directly observable; any remaining unobserved differences can still bias the estimate of the causal effect.

**2F.Q3** Describe why the treatment estimate represents the `Average Treatment for the Treated (ATT)` and explain why this is the case relative to estimation of the `Average Treatment Effect (ATE)`.

*Response:* The treatment estimate represents the ATT because matching builds a comparison group that resembles the treated precincts and then estimates the effect of those precincts that actually received treatment. Essentially, the counterfactual outcome (ie. what would have occurred alternatively as observed in the control group) is built to reflect what would have happened to treated units had they not actually been treated. Contrarily, the ATE averages effects over the entire population (both treated and untreated) which requires modeling outcomes for units (ex. precincts) that may be very different from those with turbine projects.

------------------------------------------------------------------------

### Part 3: Panel Data, Fixed Effects, and Difference-in-Difference

**Data source:** [Dataverse-Stokes2015](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDUGCC)

------------------------------------------------------------------------

#### **3A:** Read in the panel data + code variables `precinct_id` and `year` as factors

```{r}

panel_data <- read.csv("data/Stokes15_panel_data.csv")
panel_data <- panel_data %>% 
    mutate(precinct_id = as.factor(precinct_id), year = as.factor(year)) 

# HINT: Try running `tabyl(panel_data$year)`. Review article to make sense of the row numbers (n).
tabyl(panel_data$year)
```

**3A.Q1:** Why are there 18,558 rows in `panel_data`?

*Response:* There are about 6,186 precincts per each year recorded (2003, 2007, and 2011), resulting in a total of 18,558 precincts recorded in the data set.

```{r}
# How many years are included in the panel?
length(unique(panel_data$year))
# How many precincts are there?
panel_data %>% group_by(year) %>% summarize(num_precinct = n())
```

**3A.Q2:** How many unique precincts are *ever treated* (i.e., `proposed` & `operational`)?

*Response:* There are 236 unique precincts that are ever treated.

```{r}
panel_data %>%
  group_by(precinct_id) %>%
  summarise(
    ever_proposed    = any(proposed_turbine == 1, na.rm = TRUE),
    ever_operational = any(operational_turbine == 1, na.rm = TRUE),
    .groups = "drop") %>%
  summarise(
    n_ever_proposed    = sum(ever_proposed),
    n_ever_operational = sum(ever_operational))

```

------------------------------------------------------------------------

#### **3B.** Plot and evaluate parallel trends: Replicate `Figure.2` (Stokes, 2015)

1.  Create indicators for whether each precinct is ever treated by 2011 (`treat_p`, `treat_o`; separate indicator for proposals and operational turbines).
2.  Plot mean incumbent vote share by year for treated vs control precincts (with 95% CIs).
3.  Facet by turbine type (proposed & operational)

Step 1: Prepare data

```{r}

trends_data <- panel_data %>%
  group_by(precinct_id) %>%
  mutate(
    treat_p = as.integer(any(proposed_turbine == 1, na.rm = TRUE)),  # ever proposed (in any year)
    treat_o = as.integer(any(operational_turbine == 1, na.rm = TRUE))) %>% # ever operational (in any year)
  ungroup() %>% 
  pivot_longer(c(treat_p, treat_o),
               names_to = "turbine_type", values_to = "treat") %>% 
  mutate(
      turbine_type = factor(turbine_type,
                            levels = c("treat_p", "treat_o"),
                            labels = c("Proposed turbines", "Operational turbines")),  
    status = if_else(treat == 1, "Treated", "Control"),
    year   = factor(year))

```

Step 2: Create trends plot

```{r}

pd <- position_dodge(width = 0.15)

trends_data %>%
  group_by(turbine_type, status, year) %>%
  summarise(
    mean = mean(perc_lib, na.rm = TRUE),
    n    = sum(!is.na(perc_lib)),
    se   = sd(perc_lib, na.rm = TRUE) / sqrt(n), 
    ci   = qt(.975, df = pmax(n - 1, 1)) * se,
    .groups = "drop") %>%
ggplot(aes(year, mean, color = status, group = status)) +
  geom_line(position = pd, linewidth = 1.2) +
  geom_point(position = pd, size = 2.6) +
  geom_errorbar(
    aes(ymin = mean - ci, ymax = mean + ci),
    position = pd, width = .12, linewidth = .7, color = "black") +
  facet_wrap(~ turbine_type, nrow = 1) +
  scale_color_manual(values = c(Control = "#0072B2", Treated = "#B22222")) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  coord_cartesian(ylim = c(.20, .57)) +
  labs(
    title = "Figure 2. Trends in the Governing Partyâ€™s Vote Share",
    x = "Election Year",
    y = "Liberal Party Vote Share",
    color = NULL) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.minor = element_blank(),
    legend.position = "bottom",
    strip.text = element_text(face = "bold"))

```

**3B.Q1:** Write a short paragraph assessing the parallel trends assumption for each outcome.

*Response (4-6 sentences):* The parallel trends assumption appears to hold well for the proposed turbines group but is violated for the operational turbines group. For proposed turbines, the treated and control precincts follow identical parallel paths between 2003 and 2007. In the operational group, however, the treated precincts were already declining at a steeper rate compared to the control group for changes in liberal voter share for that same period, indicating that both groups did not follow a parallel trajectory given the significant overlap. Between 2007 and 2011, the trends in liberal party vote share diverge in both groups as the treated precinncts show a steeper drop in vote share compared to the controls. This divergence after 2007 suggests that turbine projects (whether proposed or operational) cause significant electoral backlash or political punishment (ie. sharper drop in liberal party voter share) that the control groups did not experience.

------------------------------------------------------------------------

### Estimating Fixed Effects Models (DiD) for proposals

$$
\text{Y}_{it}
=  \alpha_0 +
\beta \cdot (\text{proposed_turbine}_{it})
+ \gamma_i
+ \delta_t
+ \varepsilon_{it}
$$

-   $Y_{it}$ is the vote share for the Liberal Party in precinct *i* in time *t*
-   $\beta$ is the treatment effect of a turbine being proposed within a precinct
-   $\gamma_i$ is the precinct fixed effect
-   $\delta_t$ is the year fixed effect

------------------------------------------------------------------------

### Example 1: Randomly sample 40 precincts

-   To illustrate the "dummy variable method" of estimating fixed effects using the the general `lm()` function we are going to randomly sample 40 precincts (20 "treated" precincts with proposed turbines).
-   If we attempted to use this approach with the full sample estimating all 6185 (n-1) precinct-level coefficients is impractical (it would take a long time).

```{r}
set.seed(40002026)

precinct_frame <- panel_data %>%
  group_by(precinct_id) %>%
  summarise(
    proposed_turbine_any = as.integer(any(proposed_turbine == 1, na.rm = TRUE)),
    .groups = "drop"
  )

ids_40 <- precinct_frame %>%
  group_by(proposed_turbine_any) %>%
  slice_sample(n = 20) %>%
  ungroup() %>%
  select(precinct_id)

sample_40_precincts <- panel_data %>%
  semi_join(ids_40, by = "precinct_id")

```

------------------------------------------------------------------------

#### **3C:** Estimate a fixed effects model using `lm()` with fixed effects added for `precinct` and `year` using the sample of 40 precincts just created.

```{r}
model1_ff <- lm(perc_lib ~ proposed_turbine + precinct_id + year, data = sample_40_precincts)

summ(model = model1_ff, model.fit = F, robust = T)

```

```{r}
summ(model1_ff, model.fit = FALSE, digits = 3, robust = T)
plot(model1_ff)


```

**3C.Q1:** Intuition check: Is the *signal-to-noise* ratio for the treatment estimate greater than *2-to-1*?

*Response:* The signal-to-noise ratio for the treatment estimate is less than the 2-to-1 estimate because the standard error is less than half of the distribution of the coefficient. (std\*2)\*\*

> HINT: Add the argument `digits = 3` to the `summ()` function above

**3C.Q2:** Re-run the `summ()` function using the *heteroscedasticiy robust standard error adjustment* (`robust = TRUE`). Did the standard error (S.E.) estimates change? Explain why.

*Response:* The standard error estimates changed; the SE estimates increased from the original model. This is likely because the sampled data was assumed to have normally distributed residuals; however, repeated measurements within places can introduce correlated errors (\*\*).

**3C.Q3:** Compare results of the model above to the findings from the fixed effects analysis in the Stokes (2015) study. Why might the results be similar or different?

*Response:* .

**3C.Q4:** In your own words, explain why it is advantageous from a causal inference perspective to include year and precinct fixed effects. Explain how between-level and within-level variance is relevant to the problem of omitted variable bias (OVB).

*Response (2-4 sentences):* It is necessary to include `year` and `precinct` as fixed effects to account for differences in liberal voter share overtime as well as within precincts. The liberal voter share in precincts is not necessarily dependent on time; for example, precincts could become more or less liberal based on emigrating or immigrating to and from different precincts that change the demographics of the precinct, as well as motivational and personal decisions to change individual political affiliation. Between-level variance between precincts should be accounted for to account for time-invariant differences (ie. factors not dependent on time) for changes in the liberal voter share, resulting in remaining within-level differences that are time dependent. By adding `year` as a fixed effect to the model, time-variant differences from year to year in the liberal voter share can be better accounted for to prevent OVB in within-level variance; differences in time groups are better accounted for.

------------------------------------------------------------------------

#### **3D.** Now using the full sample, estimate the treatment effect of wind turbine proposals on incumbent vote share. Use `feols()` from the `{fixest}` package to estimate the fixed effects.

See vignette here: [fixest walkthrough](https://cran.r-project.org/web/packages/fixest/vignettes/fixest_walkthrough.html#11_Estimation)

```{r}

model2_ff <- feols(perc_lib ~ proposed_turbine | precinct_id + year, 
                   data = sample_40_precincts, 
                   cluster = ~precinct_id)

summary(model2_ff)
```

**3D.Q1:** Interpret the model results and translate findings to be clear to an audience that may not have a background in causal inference (Econometrics) methods.

In panel data settings, why is clustering by precinct important (i.e., `cluster = ~precinct_id`) ?â€

*Response (4-6 sentences):*

Repeated records of liberal voter share in individual precincts may be more similar to other precincts geographicaly each other than precincts grouped farther away.\*\*

------------------------------------------------------------------------

#### **3E.** Estimate the treatment effect of *operational wind turbines* on incumbent vote share. Use the same approach as the previous model.

```{r}

model3_ff <- 

summary()
```

**3E.Q1:** Interpret the `model3_ff` results as clearly and **concisely** as you can.

*Response:* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**3E.Q2:** Why do you think the effect of proposed wind turbines is different from operational wind turbines. Develop your own theory about why incumbent vote share is affected in this way. Use the Stokes (2015) study to inform your response as needed.

*Response:* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

------------------------------------------------------------------------

```{r, message=TRUE, echo=FALSE, eval=FALSE}

library(praise); library(cowsay)

praise("${EXCLAMATION}! ðŸš€ Great work - You are ${adjective}! ðŸ’«")

say("The End", "duck")
```
